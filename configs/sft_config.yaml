model_name_or_path: "./checkpoints/pretrain"  # Could be a HF model or the pre-trained checkpoint
save_dir: "./checkpoints/sft"
data_path: "./data/sft/sample_sft.jsonl"
train_batch_size: 2
max_steps: 500
learning_rate: 5e-5
warmup_steps: 20
block_size: 256
mixed_precision: "fp16"
gradient_checkpointing: false
logging:
  logging_steps: 10
  log_dir: "./logs/sft"
  use_wandb: false
  wandb_project: "MyAdvancedLLM"
